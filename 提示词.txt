我和我的团队开发了一套系统，用于鸟类科普和鸟类保护。我们的系统使用流程如下，用户通过我们的网站首页（使用传统html、css、js构建，以及Tailwind CSS、FontAwesome）来访问两个模块功能，分别是关于鸟类的问答科普、图片科普。
其中问答科普具有基于llm模型的问答、基于知识库的问答、基于浏览器问答三种问答模式，
并且对于知识库的管理用户可以生成自己的知识库并往内部填充自然语言文档进行构建。图片科普模块功能为，用户通过上传鸟类图片，后台识别鸟类种类，并传递关键字给llm模型生成关于该鸟类的介绍。
该系统为B/S架构，只有网页端部署在用户端，而两个功能模块部署在服务器上，用户打开网页并和服务器搭建隧道可以体验该系统。

其中鸟类的问答科普的实现，通过LangChain框架和streamlit前端界面，集成ChatGLM大预言模型和m3e-base词向量切割模型，结合大语言模型，
如Vicuna, Alpaca, LLaMA, Koala, RWKV等进行问答生成，过程包括加载文件、读取文本、文本分割、文本向量化、问句向量化、
在文本向量中匹配出与问句向量最相似的top k个文档，并将其作为上下文加入到prompt中，最后通过LLM生成回答。适配多种本地向量数据库，如FAISS、milvus/pg_vector等，便利于用户的灵活使用。

鸟类图片科普的实现，使用streamlit前端界面，用户上传图片给系统，系统通过经过训练的yolov8模型识别鸟类种类和位置，并在图片中标注出来，并将识别出的鸟类种类和我们预先设置的提示词结合，送给经过微调的ChatGLM模型，生成关于该鸟类的科普。
{
yolov8预训练权重，我们总共训练了n、l、x系列，得益于yolov8对于大目标检测的优秀性能，每套训练权重都取得了优秀的结果。
}
对于yolov8模型我们进行了减枝操作。
{
约束训练：通过修改YOLOv8的代码，在训练过程中添加L1正则化，特别是对Batch Normalization（BN）层的权重和偏差进行惩罚，
以促使模型参数向0倾斜，从而达到稀疏化的目的。我们提供了详细的代码修改指南和训练命令，以及通过tensorboard可视化BN层参数的分布变化，从而优化正则化强度。

剪枝：在约束训练得到的稀疏化模型基础上，我们介绍了具体的剪枝方法和代码。剪枝过程主要是基于BN层权重的绝对值，
去除权重较小（即影响较小）的通道，以减少模型的复杂度。详细说明了如何实现剪枝，包括如何选择阈值和处理连续的卷积层。剪枝后的模型可以导出为ONNX格式，以便进一步的验证和使用。

回调训练（finetune）：剪枝后，模型需要通过回调训练来恢复（或接近）剪枝前的精度。我们提供了两种方法来避免模型在这一步骤重新加载yaml文件中的结构定义，
确保直接使用剪枝后的模型进行finetune。最后，通过命令行输入进行finetune训练。
}

关键词解释:
 Langchain:(LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。
它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。
LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。)

ChatGLM:(ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。
经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。
为了方便下游开发者针对自己的应用场景定制模型，GLM同时实现了基于 P-Tuning v2 的高效参数微调方法，INT4 量化级别下最低只需 7GB 显存即可启动微调。)

Tailwind CSS: 一个功能类优先的CSS框架，用于快速设计自定义用户界面。它提供了大量的实用工具类，使得开发者能够以更少的CSS编码构建响应式设计。在这个网页中，Tailwind CSS用于布局、间距、颜色、字体等样式的快速实现。

FontAwesome: 一个图标库和工具套件，提供了可用于网页设计的矢量图标和社交媒体图标。在这个网页上，FontAwesome用于添加视觉吸引力和提高用户界面的认知效率。

JavaScript: 用于网页的交互性功能，如点击事件处理函数rotateImage，该函数用于旋转图片效果，增加了页面的动态互动性。